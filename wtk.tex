\begin{frame}{From Distance to Kernels}
    Intuitive explanation
\end{frame}

\begin{frame}{From Distance to Kernels}
  \begin{definition}[Wasserstein time series kernel]
  \normalsize
  Let $\oneseries_i$ and $\oneseries_j$ be two time series, and $\shapelet_{i1}, \dots, \shapelet_{iU}$
  as well as $\shapelet_{j1}, \dots, \shapelet_{jV}$ be their respective
  subsequences. Moreover, let $D$ be a $U \times V$ matrix that contains
  the pairwise distances of all subsequences, such that
  %
  $D_{uv} := \dist\left(\shapelet_{iu}, \shapelet_{jv}\right)$,
  %
  where $\dist(\cdot, \cdot)$ denotes the usual Euclidean distance.
  The optimisation problem
  %
  \begin{equation}\
   \wasserstein_1\left(\oneseries_i, \oneseries_j\right) := \min_{P \in \Gamma\left(\oneseries_i, \oneseries_j\right)} \left\langle D, P \right\rangle_{\mathrm{F}},
    \label{eq:Our distance}
  \end{equation}
  %
  yields the optimal transport cost to transform $\oneseries_i$
  into $\oneseries_j$ by means of their subsequences. Then, given
  $\lambda\in\real_{> 0}$, we can define
  %
  \begin{equation}
    \Method\left(\oneseries_i, \oneseries_j\right) := \exp\left(-\lambda \wasserstein_1\left(\oneseries_i, \oneseries_j\right)\right),
    \label{eq:Our kernel}
  \end{equation}
  %
  which we refer to as our \emph{Wasserstein-based subsequence kernel};
  \end{definition}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Algorithms
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\definecolor{mydarkblue}{rgb}{0,0.08,0.45}

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\renewcommand{\algorithmiccomment}[1]{\qquad \textcolor{ETHf}{//} \textcolor{ETHf}{#1}}

\begin{frame}{\longmethod}
    \begin{algorithm}[H]
      \footnotesize
      \caption{\longmethod}
      \begin{algorithmic}[1]
        \REQUIRE{Time series for training and testing
        $\allseries_{\text{train}}$, $\allseries_{\text{test}}$; subsequence
        length $w$; kernel weight factor $\lambda$}
        \ENSURE{$\mathcal{K}^{\,\text{train}}, \mathcal{K}^{\,\text{test}}$}
          \STATE $\shapelets^{\text{train}} \gets \textsc{Subsequences}({\allseries_{\text{train}}, w})$  \COMMENT{Extract subsequences}
          \STATE $\shapelets^{\text{test}} \gets \textsc{Subsequences}({\allseries_{\text{test}}, w})$ \COMMENT{Extract subsequences}
          \FOR{$\oneseries_i \in \allseries_{\text{train}}$}
            \FOR{$\oneseries_j \in \allseries_{\text{train}}$}
              \STATE $\mathcal{D}_{ij}^{\text{train}} \gets \wasserstein_1\left(\shapelets_i^{\text{train}}, \shapelets_j^{\text{train}}\right)$ \COMMENT{Wasserstein distance calculation (train)} %\Comment{Compute Wasserstein distance between TS using subsequences}
            \ENDFOR
          \FOR{$\oneseries_k \in \allseries_{\text{test}}$}
            \STATE $\mathcal{D}_{ik}^{\text{test}} \gets \wasserstein_1\left(\shapelets_i^{\text{train}}, \shapelets_k^{\text{test}}\right)$ \COMMENT{Wasserstein distance calculation (test)} %\Comment{Compute Wasserstein distance between TS using subsequences}
            \ENDFOR
          \ENDFOR
          \STATE $\mathcal{K}^{\,\text{train}} \gets \exp\left(-\lambda \mathcal{D}^{\text{train}} \right)$ \COMMENT{Kernel matrix calculation}
          \STATE $\mathcal{K}^{\,\text{test}} \gets \exp\left(-\lambda \mathcal{D}^{\text{test}} \right)$ \COMMENT{Kernel matrix calculation}
          \RETURN $\mathcal{K}^{\,\text{train}}, \mathcal{K}^{\,\text{test}}$
      \end{algorithmic}
    \end{algorithm}
\end{frame}